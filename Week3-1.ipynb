{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53a1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e708a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995cd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 178\n",
      "1 182\n",
      "2 177\n",
      "3 183\n",
      "4 181\n",
      "5 182\n",
      "6 181\n",
      "7 179\n",
      "8 174\n",
      "9 180\n"
     ]
    }
   ],
   "source": [
    "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
    "    print(class_name, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28661de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original labels:  [1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
      "binary labels:  [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_binary_imbalanced = y.copy()\n",
    "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
    "\n",
    "print('original labels: ', y[1:30])\n",
    "print('binary labels: ', y_binary_imbalanced[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe4226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1615,  182], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_binary_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2761520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state = 0)\n",
    "\n",
    "svm = SVC(kernel = 'rbf', C=1).fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)\n",
    "\n",
    "y_predict = svm.predict(X_test)\n",
    "\n",
    "y_predict == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5162303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044444444444445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "\n",
    "y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "k = np.sum(y_test == y_dummy_predictions) # np.sum counts number of True in the boolean mask y_test == y_dummy_predictions\n",
    "accuracy = k/len(y_test)\n",
    "\n",
    "dummy_majority.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c0c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent class (dummy classifier)\n",
      " [[407   0]\n",
      " [ 43   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "y_majority_predicted = dummy_majority.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test,y_majority_predicted)\n",
    "\n",
    "print('most frequent class (dummy classifier)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6abd47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent class (dummy classifier)\n",
      " [[357  50]\n",
      " [ 39   4]]\n"
     ]
    }
   ],
   "source": [
    "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
    "\n",
    "y_classprop_predicted = dummy_classprop.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test,y_classprop_predicted)\n",
    "\n",
    "print('most frequent class (dummy classifier)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957b29a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent class (svm classifier)\n",
      " [[402   5]\n",
      " [  5  38]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear',C=1).fit(X_train, y_train)\n",
    "\n",
    "svm_predicted = svm.predict(X_test)\n",
    "confusion = confusion_matrix(y_test,svm_predicted)\n",
    "\n",
    "print('most frequent class (svm classifier)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3392e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 0.07\n",
      "Recall: 0.09\n",
      "F1 score: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_classprop_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_classprop_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_classprop_predicted)))\n",
    "print('F1 score: {:.2f}'.format(f1_score(y_test, y_classprop_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e2e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.99      0.99      0.99       407\n",
      "           1       0.88      0.88      0.88        43\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.94      0.94      0.94       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "dummy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.90      0.88      0.89       407\n",
      "           1       0.07      0.09      0.08        43\n",
      "\n",
      "    accuracy                           0.80       450\n",
      "   macro avg       0.49      0.49      0.49       450\n",
      "weighted avg       0.82      0.80      0.81       450\n",
      "\n",
      "dummy majority:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.90      1.00      0.95       407\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.90       450\n",
      "   macro avg       0.45      0.50      0.47       450\n",
      "weighted avg       0.82      0.90      0.86       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Program Files\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Program Files\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Program Files\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('svm:')\n",
    "print(classification_report(y_test,svm_predicted,target_names=['not 1','1']))\n",
    "print('dummy:')\n",
    "print(classification_report(y_test,y_classprop_predicted,target_names=['not 1','1']))\n",
    "print('dummy majority:')\n",
    "print(classification_report(y_test,y_majority_predicted,target_names=['not 1','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eadfb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Program Files\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, -29.828770502888116),\n",
       " (0, -19.382789738053784),\n",
       " (0, -29.198670349715567),\n",
       " (0, -21.746404459790504),\n",
       " (0, -22.64235310102342),\n",
       " (0, -11.805842369075759),\n",
       " (1, 6.495997717246041),\n",
       " (0, -23.35467639948811),\n",
       " (0, -27.5442267850303),\n",
       " (0, -26.88820425754935),\n",
       " (0, -31.863267982040266),\n",
       " (0, -22.48602744407303),\n",
       " (0, -25.318060176866066),\n",
       " (0, -13.384469430324788),\n",
       " (0, -13.565681390836076),\n",
       " (0, -13.30829484317648),\n",
       " (1, 12.18111062994153),\n",
       " (0, -34.362361855034976),\n",
       " (0, -13.231587724821603),\n",
       " (0, -29.594035340820167)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "y_scores_lr = lr().fit(X_train,y_train).decision_function(X_test)\n",
    "y_scores_list = list(zip(y_test[0:20],y_scores_lr[0:20]))\n",
    "\n",
    "y_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55fde7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Program Files\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1.1105281422944705e-13),\n",
       " (0, 3.820862166051439e-09),\n",
       " (0, 2.0853482323256512e-13),\n",
       " (0, 3.594649427724256e-10),\n",
       " (0, 1.4674083663646533e-10),\n",
       " (0, 7.4607856827615285e-06),\n",
       " (1, 0.9984928066217791),\n",
       " (0, 7.197686272776271e-11),\n",
       " (0, 1.0906723390476288e-12),\n",
       " (0, 2.10184779111985e-12),\n",
       " (0, 1.451972998094963e-14),\n",
       " (0, 1.71570398915917e-10),\n",
       " (0, 1.0104298618070975e-11),\n",
       " (0, 1.538856470204047e-06),\n",
       " (0, 1.2838044335177512e-06),\n",
       " (0, 1.6606582403928e-06),\n",
       " (1, 0.9999948736454032),\n",
       " (0, 1.1929324742457014e-15),\n",
       " (0, 1.7930553067677074e-06),\n",
       " (0, 1.4043448120828546e-13),\n",
       " (0, 3.0489349713047584e-11),\n",
       " (0, 1.5103024072372098e-07),\n",
       " (0, 6.756693459140514e-14),\n",
       " (0, 4.125268816341987e-05),\n",
       " (0, 1.032705450640122e-17),\n",
       " (0, 1.772306087145626e-09),\n",
       " (0, 2.359495536221842e-09),\n",
       " (0, 1.0729197005818194e-19),\n",
       " (0, 1.1825156148715618e-17),\n",
       " (0, 8.926304754869694e-15),\n",
       " (0, 9.360633781830224e-10),\n",
       " (0, 2.5441086753176074e-13),\n",
       " (0, 7.561746748831151e-07),\n",
       " (0, 0.004455613538202336),\n",
       " (0, 7.977932221281563e-08),\n",
       " (0, 1.4706568472495285e-11),\n",
       " (0, 1.0958967053528686e-12),\n",
       " (1, 0.056109728423460695),\n",
       " (0, 3.169632097308303e-10),\n",
       " (1, 0.999999980207898),\n",
       " (0, 0.0001339769679596887),\n",
       " (0, 2.2382687895700536e-06),\n",
       " (0, 2.82349171493081e-15),\n",
       " (0, 1.5553075623546453e-15),\n",
       " (1, 0.4221191537521913),\n",
       " (0, 1.2675485896469129e-15),\n",
       " (0, 1.5526407016153087e-13),\n",
       " (0, 6.807232054950889e-11),\n",
       " (0, 1.291976453899179e-11),\n",
       " (1, 0.9965597373039711),\n",
       " (0, 6.31487278899214e-15),\n",
       " (0, 3.7178605664656796e-05),\n",
       " (0, 1.5106437867652511e-13),\n",
       " (0, 3.6466206564994685e-13),\n",
       " (0, 2.4796949230811526e-16),\n",
       " (0, 7.682509421144062e-16),\n",
       " (0, 5.709016549194555e-05),\n",
       " (1, 0.0758171543205436),\n",
       " (0, 4.709809057029894e-14),\n",
       " (0, 2.1634202720192243e-15),\n",
       " (0, 1.1139978982582764e-07),\n",
       " (0, 0.000179885804333972),\n",
       " (0, 4.235651024966085e-05),\n",
       " (0, 2.1301848041405965e-09),\n",
       " (1, 0.996697074398313),\n",
       " (0, 1.4895535437237791e-15),\n",
       " (0, 5.6510021559936e-07),\n",
       " (0, 5.829510762400246e-05),\n",
       " (0, 4.473940650636414e-07),\n",
       " (1, 0.9853977835043333),\n",
       " (0, 0.006678814534054217),\n",
       " (0, 2.2525843115835898e-09),\n",
       " (0, 1.3842682133266837e-17),\n",
       " (1, 0.9999999932123496),\n",
       " (0, 4.183779691612263e-14),\n",
       " (0, 0.18367179920143253),\n",
       " (0, 3.920309056399557e-13),\n",
       " (0, 2.5317610156775067e-06),\n",
       " (0, 1.6761419509004584e-16),\n",
       " (0, 6.183231952842446e-15),\n",
       " (0, 0.9999848733502528),\n",
       " (0, 1.3913946847959302e-14),\n",
       " (0, 7.797098659938238e-06),\n",
       " (0, 1.3839324940888836e-18),\n",
       " (0, 6.586117910789489e-11),\n",
       " (0, 1.0533111863114442e-09),\n",
       " (0, 1.7580848608580241e-06),\n",
       " (0, 1.7689022678276785e-16),\n",
       " (1, 0.8747696206412832),\n",
       " (0, 1.9472614369091236e-16),\n",
       " (0, 2.300539939142332e-08),\n",
       " (0, 1.9939484532753623e-11),\n",
       " (0, 1.7543158201823846e-10),\n",
       " (1, 0.9999778602996308),\n",
       " (0, 0.9037524530074382),\n",
       " (0, 7.61425187861685e-07),\n",
       " (0, 1.3502673276562673e-06),\n",
       " (0, 3.061335039788548e-07),\n",
       " (0, 8.71200482828934e-06),\n",
       " (0, 0.00012925546922619606),\n",
       " (0, 1.5374350906995738e-18),\n",
       " (0, 3.662598429132378e-12),\n",
       " (0, 8.559189628804728e-09),\n",
       " (0, 2.734399207758264e-11),\n",
       " (0, 4.1490957136057645e-12),\n",
       " (0, 7.622617600909823e-14),\n",
       " (0, 7.965783198318988e-10),\n",
       " (1, 0.9999351877934816),\n",
       " (0, 6.465839601722004e-16),\n",
       " (0, 0.6326881067256337),\n",
       " (0, 1.4381360055557865e-05),\n",
       " (0, 5.45580456322719e-13),\n",
       " (0, 1.6732013206236612e-09),\n",
       " (0, 1.5943747656000554e-14),\n",
       " (0, 2.2757230557699746e-07),\n",
       " (0, 1.5512182393720193e-07),\n",
       " (0, 1.2633976303718144e-13),\n",
       " (0, 3.44734397685862e-15),\n",
       " (0, 0.006207908823541552),\n",
       " (0, 7.020706573261315e-05),\n",
       " (0, 6.156187781747092e-17),\n",
       " (0, 7.590696082848802e-06),\n",
       " (0, 1.3450987733099215e-06),\n",
       " (0, 9.072328466092153e-09),\n",
       " (0, 0.23093637362434605),\n",
       " (0, 1.0623157667490968e-11),\n",
       " (0, 3.669282512657678e-16),\n",
       " (0, 2.5663021613958654e-09),\n",
       " (1, 0.6304083815288101),\n",
       " (0, 1.0892767509144128e-08),\n",
       " (0, 1.217560667029605e-07),\n",
       " (0, 0.00805167536815388),\n",
       " (0, 3.827459101033895e-06),\n",
       " (0, 1.3640270135645791e-09),\n",
       " (0, 4.805900823746548e-09),\n",
       " (0, 3.1759376888802014e-15),\n",
       " (0, 7.569783764410471e-10),\n",
       " (0, 3.857696692770709e-12),\n",
       " (0, 0.0017671685804231255),\n",
       " (0, 4.248144656295167e-08),\n",
       " (0, 0.0027478699291953244),\n",
       " (0, 4.980884567693775e-10),\n",
       " (0, 1.147172070907322e-07),\n",
       " (0, 1.7575288895303307e-10),\n",
       " (0, 8.55215488415651e-13),\n",
       " (1, 0.9999998903080445),\n",
       " (0, 6.632393677585745e-16),\n",
       " (1, 0.9788778189608038),\n",
       " (0, 0.0008800009277375166),\n",
       " (0, 8.280147323865853e-15),\n",
       " (0, 2.012282990037395e-12),\n",
       " (1, 0.9784563842798292),\n",
       " (0, 1.3461971911701542e-09),\n",
       " (0, 2.1783384656371882e-17),\n",
       " (0, 3.1429930124714546e-10),\n",
       " (1, 0.8808146908918635),\n",
       " (0, 1.3643762014186558e-10),\n",
       " (0, 1.4331633463755338e-05),\n",
       " (0, 0.0001347291393037459),\n",
       " (0, 1.5963382060361557e-10),\n",
       " (0, 2.3423750853564725e-07),\n",
       " (0, 4.136264870992771e-05),\n",
       " (0, 1.3998045500016028e-11),\n",
       " (0, 1.4095885488780686e-14),\n",
       " (0, 4.5337852611004705e-07),\n",
       " (0, 4.80455027828061e-13),\n",
       " (0, 0.24280750292362482),\n",
       " (0, 5.893644122607556e-05),\n",
       " (0, 7.620904738075514e-08),\n",
       " (0, 1.637109055361331e-07),\n",
       " (0, 1.151951730169227e-06),\n",
       " (1, 0.9996591520311758),\n",
       " (0, 1.3903599463759383e-12),\n",
       " (0, 3.7029554081501515e-08),\n",
       " (1, 0.9992288616728947),\n",
       " (0, 2.2625155469335376e-09),\n",
       " (0, 2.874191821614422e-17),\n",
       " (0, 4.3827608871606097e-10),\n",
       " (0, 1.0601330666072218e-13),\n",
       " (0, 4.278862273950748e-14),\n",
       " (0, 9.060292763618652e-10),\n",
       " (0, 0.06253704429385505),\n",
       " (0, 1.0107722835574222e-12),\n",
       " (0, 6.74542491506034e-18),\n",
       " (0, 2.25741315703104e-21),\n",
       " (0, 2.3527444972757805e-11),\n",
       " (0, 9.048809599635904e-14),\n",
       " (0, 3.965973726927342e-20),\n",
       " (0, 2.0313765331128843e-09),\n",
       " (0, 6.092141488514863e-14),\n",
       " (0, 2.0566322424342168e-13),\n",
       " (0, 6.385588085772417e-08),\n",
       " (0, 6.803085323742893e-13),\n",
       " (0, 2.015000066001964e-08),\n",
       " (0, 1.5394902075849058e-19),\n",
       " (0, 9.978639828368624e-11),\n",
       " (0, 0.9998584369203385),\n",
       " (0, 1.2888450994281323e-19),\n",
       " (0, 1.7929948554929845e-12),\n",
       " (0, 8.123653466598256e-14),\n",
       " (0, 0.00048029309629669107),\n",
       " (0, 1.2346570494872037e-15),\n",
       " (1, 0.9996646135978569),\n",
       " (0, 3.6323825796983787e-09),\n",
       " (0, 4.8186778516909795e-05),\n",
       " (0, 0.0038872202889261406),\n",
       " (0, 1.7880190941697738e-14),\n",
       " (0, 2.792662514332156e-12),\n",
       " (0, 5.6087525895801404e-15),\n",
       " (0, 3.3434229520058346e-13),\n",
       " (0, 3.70951577239736e-13),\n",
       " (0, 0.0048017945119563955),\n",
       " (0, 5.524825340419843e-08),\n",
       " (1, 0.07156213237414404),\n",
       " (0, 4.2426904888839974e-12),\n",
       " (0, 4.444888314498828e-06),\n",
       " (1, 0.999997772397077),\n",
       " (0, 0.09654357817181428),\n",
       " (0, 0.0004337711750698973),\n",
       " (0, 3.654622729869467e-17),\n",
       " (0, 8.4449746769607e-12),\n",
       " (0, 2.7886178570229187e-08),\n",
       " (0, 5.261637857961937e-07),\n",
       " (0, 9.677807088773093e-10),\n",
       " (0, 0.0018975044654009601),\n",
       " (0, 6.341857119688126e-10),\n",
       " (0, 7.12671442792118e-05),\n",
       " (0, 4.390762636862591e-14),\n",
       " (0, 9.194125920399395e-08),\n",
       " (1, 0.9924951856655541),\n",
       " (0, 1.038862901704339e-08),\n",
       " (0, 2.057457025712866e-18),\n",
       " (0, 8.909872374718714e-23),\n",
       " (0, 4.051715225880899e-17),\n",
       " (0, 3.2154619076121436e-11),\n",
       " (0, 3.170973513357805e-14),\n",
       " (0, 1.1335973375280806e-09),\n",
       " (0, 3.340719534739211e-17),\n",
       " (0, 4.7763810178918306e-20),\n",
       " (0, 1.560647604371931e-10),\n",
       " (1, 0.9980884553133179),\n",
       " (1, 0.9996527143045041),\n",
       " (0, 1.6081555303908208e-09),\n",
       " (0, 8.87958920795407e-12),\n",
       " (0, 1.8092482261007114e-07),\n",
       " (0, 5.113285790382233e-07),\n",
       " (0, 0.06825184855076205),\n",
       " (0, 1.2182865586287169e-09),\n",
       " (0, 8.026154393044327e-13),\n",
       " (0, 7.627126013471747e-07),\n",
       " (0, 2.520320685076439e-06),\n",
       " (0, 2.6357307817080493e-21),\n",
       " (0, 1.7098177616091426e-07),\n",
       " (0, 3.0899738521898155e-12),\n",
       " (0, 8.526392432989931e-08),\n",
       " (0, 8.16232826541746e-14),\n",
       " (0, 6.006771123558856e-08),\n",
       " (0, 3.901354173027332e-08),\n",
       " (0, 9.984200357757082e-12),\n",
       " (0, 1.7383193345381675e-11),\n",
       " (0, 2.2922941184730887e-07),\n",
       " (1, 0.6023048276835962),\n",
       " (0, 2.3059199938523123e-06),\n",
       " (0, 0.944424567636377),\n",
       " (0, 4.497323401571611e-15),\n",
       " (0, 1.773490738600791e-10),\n",
       " (0, 8.874430774446913e-07),\n",
       " (0, 0.00011770514794370064),\n",
       " (0, 1.7057571305561347e-05),\n",
       " (0, 1.1976583089193039e-14),\n",
       " (0, 1.4118127511710705e-10),\n",
       " (0, 1.5284406951796943e-09),\n",
       " (0, 3.2061999196081414e-09),\n",
       " (0, 1.2337573352941935e-06),\n",
       " (0, 5.428708325446457e-22),\n",
       " (0, 0.013186751211961764),\n",
       " (0, 1.5730253544937994e-09),\n",
       " (0, 0.0044226429343747565),\n",
       " (0, 4.252915085332207e-05),\n",
       " (0, 2.2431941621481064e-14),\n",
       " (0, 2.9035621880952233e-12),\n",
       " (0, 1.300956635257482e-09),\n",
       " (0, 1.3254806166638847e-10),\n",
       " (0, 2.2675368466764335e-07),\n",
       " (0, 2.595739208221773e-09),\n",
       " (0, 0.01788024419094717),\n",
       " (0, 3.888318131425745e-11),\n",
       " (0, 5.501516049674862e-13),\n",
       " (0, 1.0317638075884163e-11),\n",
       " (0, 4.636094617685909e-09),\n",
       " (0, 1.4393789954683313e-10),\n",
       " (0, 1.7090956361316728e-12),\n",
       " (0, 3.6789305719792585e-08),\n",
       " (0, 3.235431448068439e-18),\n",
       " (0, 2.3254416235249953e-15),\n",
       " (0, 9.16698224138249e-05),\n",
       " (0, 9.062760320827049e-12),\n",
       " (0, 2.1008848488069078e-07),\n",
       " (0, 5.979249017997691e-07),\n",
       " (0, 1.2389067715297328e-07),\n",
       " (0, 9.563522205547147e-18),\n",
       " (1, 0.02684778596106359),\n",
       " (0, 8.715867036852883e-08),\n",
       " (0, 2.837164357822011e-11),\n",
       " (0, 1.9948625791767096e-13),\n",
       " (0, 7.233229109352987e-07),\n",
       " (0, 2.1891182604264513e-11),\n",
       " (0, 6.245172928116844e-17),\n",
       " (0, 2.8969758286661645e-13),\n",
       " (0, 9.235691745762898e-06),\n",
       " (0, 3.4569489456481454e-18),\n",
       " (0, 7.054439946280678e-08),\n",
       " (0, 1.169699659892721e-08),\n",
       " (0, 9.24137676954122e-12),\n",
       " (0, 2.7212755954531583e-10),\n",
       " (0, 7.222437502334913e-08),\n",
       " (0, 4.395791296606736e-13),\n",
       " (0, 3.123535171472081e-08),\n",
       " (0, 1.1424845299189475e-15),\n",
       " (0, 2.470334219246849e-08),\n",
       " (0, 4.444201232803371e-08),\n",
       " (0, 3.419172861598204e-15),\n",
       " (0, 7.69715550044742e-12),\n",
       " (0, 2.2625832358886618e-10),\n",
       " (0, 0.00015995710095933452),\n",
       " (1, 0.45947157966245167),\n",
       " (0, 1.8639183308210482e-06),\n",
       " (1, 0.9999962608215307),\n",
       " (0, 7.611583118772662e-17),\n",
       " (0, 2.374619089133075e-05),\n",
       " (0, 2.0390309881225642e-10),\n",
       " (1, 0.005543266808770702),\n",
       " (0, 1.099792845266939e-10),\n",
       " (0, 1.8625370536461298e-09),\n",
       " (0, 2.1067016429949694e-14),\n",
       " (0, 1.0900422310419645e-06),\n",
       " (0, 8.698175997069003e-08),\n",
       " (0, 1.6430032431934024e-12),\n",
       " (0, 3.686285532733876e-14),\n",
       " (1, 0.999044555452606),\n",
       " (0, 0.10812802058927692),\n",
       " (1, 0.999996516238476),\n",
       " (0, 1.9374674722736715e-10),\n",
       " (0, 0.00020536317436797792),\n",
       " (0, 0.017981853118462565),\n",
       " (0, 1.672031769219179e-12),\n",
       " (0, 3.696186383666476e-12),\n",
       " (0, 1.016193337210477e-08),\n",
       " (1, 0.951523668736155),\n",
       " (1, 0.9594547968687327),\n",
       " (0, 8.357380985307997e-12),\n",
       " (0, 5.1857925860575165e-14),\n",
       " (0, 5.360527769440022e-09),\n",
       " (0, 1.7448539698858312e-16),\n",
       " (0, 2.539920986610776e-10),\n",
       " (0, 3.0748555392510756e-13),\n",
       " (0, 4.921224620275033e-14),\n",
       " (0, 1.1138242012762295e-09),\n",
       " (0, 0.005225888975829049),\n",
       " (0, 7.903839530954848e-09),\n",
       " (0, 1.5513358943510295e-12),\n",
       " (0, 1.849320609194636e-10),\n",
       " (0, 1.0579080103356351e-17),\n",
       " (0, 4.4023334361338376e-08),\n",
       " (0, 1.0870134365765467e-12),\n",
       " (0, 1.7835636477452114e-05),\n",
       " (0, 3.656079624116685e-14),\n",
       " (0, 7.838548017974616e-07),\n",
       " (0, 1.3092319018757168e-11),\n",
       " (0, 2.917797452659055e-14),\n",
       " (0, 9.605584002258651e-09),\n",
       " (0, 6.397519782455684e-11),\n",
       " (0, 1.9929319448855507e-15),\n",
       " (0, 7.188699887486679e-15),\n",
       " (0, 7.988010571276075e-08),\n",
       " (0, 6.590186882740743e-08),\n",
       " (0, 2.106573020073446e-14),\n",
       " (0, 2.496765602316798e-13),\n",
       " (0, 2.802593238703535e-17),\n",
       " (0, 1.5109190020699797e-06),\n",
       " (1, 0.9246472617480995),\n",
       " (0, 9.760232240202492e-05),\n",
       " (0, 3.301240625149073e-07),\n",
       " (0, 5.00695658855228e-15),\n",
       " (0, 1.1018650012832304e-14),\n",
       " (0, 4.9365681121991456e-05),\n",
       " (0, 6.325479539307655e-11),\n",
       " (0, 2.8155556312127556e-15),\n",
       " (0, 2.4694550976216975e-06),\n",
       " (0, 2.4776679607827827e-12),\n",
       " (0, 1.0235406268216273e-15),\n",
       " (0, 7.44294289792625e-06),\n",
       " (0, 6.1879877706069506e-15),\n",
       " (0, 3.901805849453865e-11),\n",
       " (0, 3.2975603028459443e-09),\n",
       " (0, 1.1662855234622075e-06),\n",
       " (0, 1.3686386560442199e-19),\n",
       " (0, 1.6627987405332796e-10),\n",
       " (0, 0.9991012120750433),\n",
       " (0, 1.6657430708569424e-12),\n",
       " (0, 0.07642920632091488),\n",
       " (0, 2.194768582903068e-09),\n",
       " (0, 5.457286428655461e-14),\n",
       " (0, 1.2516579070846706e-11),\n",
       " (0, 5.694943563564946e-08),\n",
       " (0, 0.00015555498833203359),\n",
       " (0, 6.998984073717156e-14),\n",
       " (0, 0.00016684095173216708),\n",
       " (1, 0.9823415928547256),\n",
       " (0, 1.0908940916265455e-13),\n",
       " (0, 2.744977396148613e-20),\n",
       " (0, 1.4335396025177106e-06),\n",
       " (0, 1.1485931613094206e-15),\n",
       " (0, 1.2947582864786982e-07),\n",
       " (0, 3.8950581734394253e-14),\n",
       " (0, 0.0004070653555539294),\n",
       " (1, 0.7307331345205492),\n",
       " (0, 2.0805740229898023e-07),\n",
       " (0, 3.986052287836194e-08),\n",
       " (0, 8.221596885746372e-19),\n",
       " (1, 0.9950286665135863),\n",
       " (0, 7.681804425533296e-14),\n",
       " (0, 1.2579941045005712e-09),\n",
       " (0, 0.23475010257857093),\n",
       " (0, 9.848454206963628e-13),\n",
       " (0, 6.109052988723267e-09),\n",
       " (0, 1.028792500291497e-14),\n",
       " (0, 1.0778894064318595e-13),\n",
       " (0, 5.964482271337744e-13),\n",
       " (0, 6.1858869365649684e-21),\n",
       " (0, 3.453528495875287e-12),\n",
       " (0, 1.2504765857865272e-24),\n",
       " (0, 1.5702766379634702e-11),\n",
       " (0, 9.888136381894961e-08),\n",
       " (1, 0.9999841334563745),\n",
       " (0, 7.347447999971741e-11),\n",
       " (0, 5.621804391811827e-13),\n",
       " (0, 0.001654158983985563),\n",
       " (0, 2.0001430515045905e-15),\n",
       " (0, 5.177648857821048e-09),\n",
       " (0, 1.1115421279651062e-09),\n",
       " (1, 0.40710136397984736),\n",
       " (0, 7.455731197227405e-11),\n",
       " (0, 0.0004298984118277604),\n",
       " (1, 0.9991517170821036),\n",
       " (0, 2.2302518086485006e-11),\n",
       " (0, 1.0990540694337495e-08),\n",
       " (0, 5.945021174491245e-07),\n",
       " (1, 0.9999829806854371),\n",
       " (0, 2.216906197204018e-19)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_lr = lr().fit(X_train,y_train).predict_proba(X_test)\n",
    "y_proba_list = list(zip(y_test,y_proba_lr[:,1]))\n",
    "\n",
    "y_proba_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
